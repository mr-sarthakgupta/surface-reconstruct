{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from skimage import measure\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "# import your libraries\n",
    "\n",
    "from IGR.code.model.network import ImplicitNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model and optimizer\n",
    "model = ImplicitNet(d_in = 3, dims = [ 512, 512, 512, 512, 512, 512, 512, 512 ], skip_in = [4], geometric_init = True)\n",
    "opt = torch.optim.Adam(\n",
    "            [\n",
    "                {\n",
    "                    \"params\": model.parameters(),\n",
    "                    \"lr\": 0.0003,\n",
    "                    \"weight_decay\": 0\n",
    "                },\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pointcloud(filename):\n",
    "    pcd = o3d.io.read_point_cloud(filename)\n",
    "    points = torch.tensor(np.asarray(pcd.points), dtype=torch.float32)\n",
    "    return points\n",
    "    \n",
    "def write_mesh(v,f,filename):\n",
    "    mesh = o3d.geometry.TriangleMesh(o3d.utility.Vector3dVector(v),o3d.utility.Vector3iVector(f))\n",
    "    o3d.io.write_triangle_mesh(filename,mesh)\n",
    "    \n",
    "def write_pointcloud(p,filename):\n",
    "    pc = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(p))\n",
    "    o3d.io.write_point_cloud(filename,pc)\n",
    "\n",
    "# class ImplcitNetwork(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         pass\n",
    "\n",
    "#     def phase_loss(self, x):\n",
    "#         pass\n",
    "\n",
    "class PHASELoss(nn.Module):\n",
    "    def __init__(self, epsilon=0.01, lambda_val=0.1, mu=0.1, ball_radius=0.01, iter_points = 50, use_normals=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            epsilon: Regularization parameter that controls smoothness\n",
    "            lambda_val: Weight for the reconstruction loss\n",
    "            mu: Weight for the normal/gradient constraint loss\n",
    "            ball_radius: Radius of balls around point samples for reconstruction loss\n",
    "            use_normals: If True, uses provided normals; otherwise enforces unit gradients\n",
    "        \"\"\"\n",
    "        super(PHASELoss, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.lambda_val = lambda_val\n",
    "        self.mu = mu\n",
    "        self.ball_radius = ball_radius\n",
    "        self.use_normals = use_normals\n",
    "        \n",
    "    def double_well_potential(self, x):\n",
    "        return torch.mean(x**2 - 2*torch.abs(x) + 1)\n",
    "    \n",
    "    def reconstruction_loss(self, u, points, sample_count=10):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            u: Neural network representing the signed density\n",
    "            points: Input point cloud (B x N x 3)\n",
    "            sample_count: Number of points to sample in each ball\n",
    "        \"\"\"\n",
    "        \n",
    "        og_points = points.clone()\n",
    "\n",
    "        random_offsets = torch.rand((sample_count, og_points.shape[-1]))\n",
    "        random_offsets = random_offsets / torch.norm(random_offsets, dim=-1, keepdim=True)\n",
    "        # random_offsets = random_offsets * self.ball_radius * torch.rand_like(random_offsets[..., :1])\n",
    "        random_offsets = random_offsets * self.ball_radius \n",
    "\n",
    "        # Sample points within balls\n",
    "        points = og_points.unsqueeze(1).expand(-1, sample_count, -1) + random_offsets.unsqueeze(0).expand(og_points.shape[0], -1, -1).cuda()\n",
    "        \n",
    "        u_values = []\n",
    "        for point in points:\n",
    "            u_values.append(u(points).mean().abs())\n",
    "\n",
    "        return torch.stack(u_values, dim = 0).mean()\n",
    "\n",
    "    def w(self, epsilon, u, x):\n",
    "        return -1 * sqrt(self.epsilon) * torch.log(1 - torch.abs(u(x))) * torch.sign(u(x))      \n",
    "\n",
    "    def normal_loss(self, u, points, normals):\n",
    "        points.requires_grad_(True)\n",
    "        if normals is None:\n",
    "            w_outs = self.w(self.epsilon, u, points)\n",
    "            grad_outputs = torch.ones_like(w_outs)\n",
    "            w_grads = torch.autograd.grad(\n",
    "                outputs=w_outs,\n",
    "                inputs=points,\n",
    "                grad_outputs=grad_outputs,\n",
    "                create_graph=True,\n",
    "                retain_graph=True,\n",
    "                only_inputs=True\n",
    "            )[0]\n",
    "            return torch.mean(torch.norm(1 - torch.norm(w_grads, p = 2, dim = -1), p = 1, dim = -1) ** 2)\n",
    "\n",
    "        if normals is not None:\n",
    "            w_outs = self.w(self.epsilon, u, points)\n",
    "            grad_outputs = torch.ones_like(w_outs)\n",
    "            w_grads = torch.autograd.grad(\n",
    "                outputs=w_outs,\n",
    "                inputs=points,\n",
    "                grad_outputs=grad_outputs,\n",
    "                create_graph=True,\n",
    "                retain_graph=True,\n",
    "                only_inputs=True\n",
    "            )[0]\n",
    "            return torch.mean(torch.norm(normals - w_grads, p = 2, dim = -1) ** 2)\n",
    "\n",
    "    \n",
    "    def gradient_loss(self, u, points, dim_range):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            u: Neural network representing the signed density\n",
    "            w: Log-transformed function (-sqrt(epsilon) * log(1-|u|) * sign(u))\n",
    "            range: Input point cloud\n",
    "            normals: Surface normals (optional)\n",
    "        \"\"\"\n",
    "        inte = torch.zeros((points.shape[0]))\n",
    "\n",
    "        # Create 3D grid from the provided range\n",
    "        x_min, x_max = dim_range[0], dim_range[1]\n",
    "        y_min, y_max = dim_range[0], dim_range[1]\n",
    "        z_min, z_max = dim_range[0], dim_range[1]\n",
    "\n",
    "        steps = 10  # Number of steps in each dimension\n",
    "        x_vals = torch.linspace(x_min, x_max, steps)\n",
    "        y_vals = torch.linspace(y_min, y_max, steps)\n",
    "        z_vals = torch.linspace(z_min, z_max, steps)\n",
    "\n",
    "        # Volume element for integration\n",
    "        dx = (x_max - x_min) / steps\n",
    "        dy = (y_max - y_min) / steps\n",
    "        dz = (z_max - z_min) / steps\n",
    "        volume_element = dx * dy * dz\n",
    "\n",
    "        for i in range(steps):\n",
    "            for j in range(steps):\n",
    "                for k in range(steps):\n",
    "                    curr_points = torch.tensor([[x_vals[i], y_vals[j], z_vals[k]]], requires_grad=True)\n",
    "                    curr_points.requires_grad_(True)\n",
    "                    u_outs = u(curr_points.cuda())\n",
    "                    \n",
    "                    # Compute gradients of w with respect to input points\n",
    "                    grad_outputs = torch.ones_like(u_outs)\n",
    "                    gradients = torch.autograd.grad(\n",
    "                        outputs=u_outs,\n",
    "                        inputs=curr_points,\n",
    "                        grad_outputs=grad_outputs,\n",
    "                        create_graph=True,\n",
    "                        retain_graph=True,\n",
    "                        only_inputs=True\n",
    "                    )\n",
    "                    \n",
    "                    inte += torch.norm(gradients[0], dim=-1, p=2)**2 * volume_element      \n",
    "\n",
    "        return inte.mean() \n",
    "        \n",
    "    def forward(self, model, points, dim_range, normals=None):\n",
    "        \"\"\"\n",
    "        Computes the complete PHASE loss\n",
    "        \n",
    "        Args:\n",
    "            model: Neural network model for signed density function\n",
    "            points: Input point cloud\n",
    "            normals: Surface normals (optional)\n",
    "        \"\"\"\n",
    "        \n",
    "        u = lambda x: model(x)\n",
    "\n",
    "        # Define the log-transformed function w (the smoothed SDF)\n",
    "        # w = lambda x: -torch.sqrt(self.epsilon) * torch.log(1 - torch.abs(u(x))) * torch.sign(u(x))      \n",
    "        \n",
    "        double_well_term = self.double_well_potential(u(points))\n",
    "        \n",
    "        # Reconstruction loss\n",
    "        recon_loss = self.reconstruction_loss(u, points)\n",
    "        \n",
    "        # gradient loss\n",
    "        gradient_loss = self.gradient_loss(u, points, dim_range)\n",
    "\n",
    "        # normal loss\n",
    "        normal_loss = self.normal_loss(u, points, normals)\n",
    "                \n",
    "        total_loss = self.epsilon * gradient_loss + double_well_term + self.lambda_val * recon_loss + self.mu * normal_loss\n",
    "\n",
    "        print(f\"total_loss: {total_loss.item()}\", f\"normal_loss: {normal_loss.item()}\", f\"gradient_loss: {gradient_loss.item()}\", f\"double_well_term: {double_well_term.item()}\", f\"recon_loss: {recon_loss.item()}\")\n",
    "\n",
    "        \n",
    "        return total_loss, {\n",
    "            'grad_term': gradient_loss,\n",
    "            'double_well': double_well_term,\n",
    "            'reconstruction': recon_loss,\n",
    "            'normal_constraint': normal_loss\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam, eps, mu = [10, 0.01, 10]\n",
    "\n",
    "\n",
    "def compute_chamfer_distance(pred_points, gt_points):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        pred_points (torch.Tensor): Predicted point cloud (N x 3)\n",
    "        gt_points (torch.Tensor): Ground truth point cloud (M x 3)\n",
    "    \"\"\"\n",
    "    # Ensure inputs are on the same device\n",
    "    device = pred_points.device\n",
    "    \n",
    "    # Compute all pairwise distances\n",
    "    pred_expanded = pred_points.unsqueeze(1)  # (N, 1, 3)\n",
    "    gt_expanded = gt_points.unsqueeze(0)      # (1, M, 3)\n",
    "    \n",
    "    # Compute squared distances\n",
    "    dist_matrix = torch.sum((pred_expanded - gt_expanded) ** 2, dim=-1)  # (N, M)\n",
    "    \n",
    "    # Compute minimum distances in both directions\n",
    "    dist_pred_to_gt = torch.min(dist_matrix, dim=1)[0]  # (N,)\n",
    "    dist_gt_to_pred = torch.min(dist_matrix, dim=0)[0]  # (M,)\n",
    "    \n",
    "    # Average the distances (symmetric Chamfer distance)\n",
    "    chamfer_dist = torch.mean(dist_pred_to_gt) + torch.mean(dist_gt_to_pred)\n",
    "    \n",
    "    return chamfer_dist.item()\n",
    "\n",
    "\n",
    "def sdf_function(epsilon, u, x):\n",
    "    return -1 * sqrt(epsilon) * torch.log(1 - torch.abs(u(x))) * torch.sign(u(x))\n",
    "\n",
    "def sample_mesh_points(mesh_path, n_points=10000):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        mesh_path (str): Path to the mesh file\n",
    "        n_points (int): Number of points to sample    \n",
    "    \"\"\"\n",
    "    mesh = o3d.io.read_triangle_mesh(mesh_path)\n",
    "    pcd = mesh.sample_points_uniformly(number_of_points=n_points)\n",
    "    points = torch.tensor(np.asarray(pcd.points), dtype=torch.float32)\n",
    "    return points\n",
    "\n",
    "def evaluate_reconstruction(model, gt_mesh_path, resolution=64, bounds=(-1.0, 1.0), n_points=10000):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: Neural network model for implicit function\n",
    "        gt_mesh_path (str): Path to ground truth mesh\n",
    "        resolution (int): Resolution for marching cubes grid\n",
    "        bounds (tuple): Min and max bounds for the grid\n",
    "        n_points (int): Number of points to sample for Chamfer distance    \n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Create grid for marching cubes\n",
    "        x = np.linspace(bounds[0], bounds[1], resolution)\n",
    "        y = np.linspace(bounds[0], bounds[1], resolution)\n",
    "        z = np.linspace(bounds[0], bounds[1], resolution)\n",
    "        \n",
    "        X, Y, Z = np.meshgrid(x, y, z, indexing='ij')\n",
    "        points = torch.tensor(np.stack([X.flatten(), Y.flatten(), Z.flatten()], axis=1), \n",
    "                              dtype=torch.float32)\n",
    "        \n",
    "        # Process in batches to avoid memory issues\n",
    "        batch_size = 10000\n",
    "        sdf_grid = []\n",
    "        for i in range(0, points.shape[0], batch_size):\n",
    "            batch_points = points[i:i+batch_size]\n",
    "            sdf_batch = sdf_function(eps, model, batch_points).detach().cpu().numpy()\n",
    "            sdf_grid.append(sdf_batch)\n",
    "        \n",
    "        sdf_grid = np.concatenate(sdf_grid, axis=0).reshape(resolution, resolution, resolution)\n",
    "        \n",
    "        # Generate mesh using marching cubes\n",
    "        v, f, _, _ = measure.marching_cubes(sdf_grid, level = 0)\n",
    "        \n",
    "        # Scale vertices back to original coordinate system\n",
    "        v = v / (resolution - 1) * (bounds[1] - bounds[0]) + bounds[0]\n",
    "        \n",
    "        # First save reconstructed mesh to temporary file\n",
    "        temp_mesh_path = 'temp_reconstruction.ply'\n",
    "        write_mesh(v, f, temp_mesh_path)\n",
    "        \n",
    "        # Sample points from both meshes\n",
    "        pred_points = sample_mesh_points(temp_mesh_path, n_points)\n",
    "        gt_points = sample_mesh_points(gt_mesh_path, n_points)\n",
    "        \n",
    "        # Compute Chamfer distance\n",
    "        chamfer_dist = compute_chamfer_distance(pred_points, gt_points)\n",
    "        \n",
    "    return chamfer_dist, v, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss: 292797.25 normal_loss: 29279.462890625 gradient_loss: 32.219120025634766 double_well_term: 0.5246445536613464 recon_loss: 0.1775328814983368\n",
      "Error in evaluation\n",
      "Iter 0/100000, Loss: 292797.250000, Grad: 32.219120, DW: 0.524645, Recon: 0.177533, Norm: 29279.462891\n",
      "total_loss: 1341486.125 normal_loss: 134147.640625 gradient_loss: 76.02800750732422 double_well_term: 0.3446275293827057 recon_loss: 0.8694436550140381\n",
      "total_loss: 679841.25 normal_loss: 67983.0 gradient_loss: 113.967041015625 double_well_term: 0.3058449327945709 recon_loss: 0.9832273721694946\n",
      "total_loss: 1943036.25 normal_loss: 194302.53125 gradient_loss: 144.6085205078125 double_well_term: 0.3856779634952545 recon_loss: 0.917301595211029\n",
      "total_loss: 201013.78125 normal_loss: 20100.439453125 gradient_loss: 161.49267578125 double_well_term: 0.5526512265205383 recon_loss: 0.7227064371109009\n",
      "total_loss: 433354.53125 normal_loss: 43334.66015625 gradient_loss: 185.22532653808594 double_well_term: 0.6263357996940613 recon_loss: 0.5444487929344177\n",
      "total_loss: 334605.4375 normal_loss: 33459.6796875 gradient_loss: 211.7378387451172 double_well_term: 0.8910654783248901 recon_loss: 0.5603915452957153\n",
      "total_loss: 426861.3125 normal_loss: 42685.359375 gradient_loss: 239.62501525878906 double_well_term: 0.9726639986038208 recon_loss: 0.43422865867614746\n",
      "total_loss: 493111.96875 normal_loss: 49310.40625 gradient_loss: 265.9981689453125 double_well_term: 1.001565933227539 recon_loss: 0.4253447651863098\n",
      "total_loss: 412470.28125 normal_loss: 41246.1796875 gradient_loss: 288.8283996582031 double_well_term: 1.1122487783432007 recon_loss: 0.4467426836490631\n",
      "total_loss: 334014.8125 normal_loss: 33400.625 gradient_loss: 312.2709045410156 double_well_term: 1.1965168714523315 recon_loss: 0.42410269379615784\n",
      "total_loss: 393667.59375 normal_loss: 39365.92578125 gradient_loss: 334.2089538574219 double_well_term: 1.2466083765029907 recon_loss: 0.375861793756485\n",
      "total_loss: 7302171.0 normal_loss: 730216.0625 gradient_loss: 357.80621337890625 double_well_term: 1.6038717031478882 recon_loss: 0.5160018801689148\n",
      "total_loss: 315577.125 normal_loss: 31557.02734375 gradient_loss: 300.3762512207031 double_well_term: 1.1289271116256714 recon_loss: 0.26974359154701233\n",
      "total_loss: 540181.0 normal_loss: 54017.3671875 gradient_loss: 257.292724609375 double_well_term: 1.2717515230178833 recon_loss: 0.34657520055770874\n",
      "total_loss: 314919.625 normal_loss: 31491.63671875 gradient_loss: 221.82720947265625 double_well_term: 0.6166147589683533 recon_loss: 0.041218917816877365\n",
      "total_loss: 3246680.0 normal_loss: 324667.65625 gradient_loss: 194.21583557128906 double_well_term: 0.5208999514579773 recon_loss: 0.10179492831230164\n",
      "total_loss: 19299132.0 normal_loss: 1929912.75 gradient_loss: 209.14224243164062 double_well_term: 0.5574093461036682 recon_loss: 0.17327472567558289\n",
      "total_loss: 6071822.5 normal_loss: 607181.5625 gradient_loss: 276.4812316894531 double_well_term: 1.152052879333496 recon_loss: 0.29091447591781616\n",
      "total_loss: 353213.21875 normal_loss: 35320.52734375 gradient_loss: 367.643798828125 double_well_term: 1.4773519039154053 recon_loss: 0.2796899676322937\n",
      "total_loss: 964959.5 normal_loss: 96494.7578125 gradient_loss: 473.69964599609375 double_well_term: 2.2303333282470703 recon_loss: 0.4973451793193817\n",
      "total_loss: 527803.75 normal_loss: 52778.90625 gradient_loss: 592.6016235351562 double_well_term: 2.6421868801116943 recon_loss: 0.6146038174629211\n",
      "total_loss: 567944.0 normal_loss: 56792.52734375 gradient_loss: 724.7178344726562 double_well_term: 3.732983350753784 recon_loss: 0.7790783643722534\n",
      "total_loss: 298764.8125 normal_loss: 29873.759765625 gradient_loss: 868.951171875 double_well_term: 5.730294227600098 recon_loss: 1.2802910804748535\n",
      "total_loss: 385672.625 normal_loss: 38564.51171875 gradient_loss: 1023.6967163085938 double_well_term: 5.646249294281006 recon_loss: 1.1627336740493774\n",
      "total_loss: 652446.375 normal_loss: 65241.26953125 gradient_loss: 1187.048583984375 double_well_term: 7.83914852142334 recon_loss: 1.3980584144592285\n",
      "total_loss: 277438.0 normal_loss: 27740.078125 gradient_loss: 1358.1417236328125 double_well_term: 8.181907653808594 recon_loss: 1.5452722311019897\n",
      "total_loss: 324303.59375 normal_loss: 32426.548828125 gradient_loss: 1534.327392578125 double_well_term: 8.544769287109375 recon_loss: 1.4213606119155884\n",
      "total_loss: 534951.625 normal_loss: 53490.6796875 gradient_loss: 1713.6988525390625 double_well_term: 11.09631061553955 recon_loss: 1.6551134586334229\n",
      "total_loss: 6839063.5 normal_loss: 683901.3125 gradient_loss: 1894.7364501953125 double_well_term: 12.342330932617188 recon_loss: 1.933924674987793\n",
      "total_loss: 259387.90625 normal_loss: 25933.525390625 gradient_loss: 2017.1724853515625 double_well_term: 13.831058502197266 recon_loss: 1.8655904531478882\n",
      "total_loss: 244537.265625 normal_loss: 24448.310546875 gradient_loss: 2136.722412109375 double_well_term: 13.320624351501465 recon_loss: 1.947346568107605\n",
      "total_loss: 442225.3125 normal_loss: 44216.0625 gradient_loss: 2252.841064453125 double_well_term: 18.777673721313477 recon_loss: 2.33658504486084\n",
      "total_loss: 952357.6875 normal_loss: 95229.2890625 gradient_loss: 2364.753662109375 double_well_term: 19.269100189208984 recon_loss: 2.192014217376709\n",
      "total_loss: 1241964.25 normal_loss: 124190.2734375 gradient_loss: 2469.886474609375 double_well_term: 16.40911865234375 recon_loss: 2.0412380695343018\n",
      "total_loss: 581933.625 normal_loss: 58185.3515625 gradient_loss: 2577.712890625 double_well_term: 25.68952178955078 recon_loss: 2.8673019409179688\n",
      "total_loss: 297036.09375 normal_loss: 29695.384765625 gradient_loss: 2681.397705078125 double_well_term: 28.663734436035156 recon_loss: 2.6762173175811768\n",
      "total_loss: 659996.6875 normal_loss: 65992.75 gradient_loss: 2779.47119140625 double_well_term: 20.25840950012207 recon_loss: 2.1137118339538574\n",
      "total_loss: 437743.53125 normal_loss: 43766.3515625 gradient_loss: 2870.90087890625 double_well_term: 26.023326873779297 recon_loss: 2.5307838916778564\n",
      "total_loss: 446628.28125 normal_loss: 44655.03515625 gradient_loss: 2956.57470703125 double_well_term: 24.693416595458984 recon_loss: 2.3667120933532715\n",
      "total_loss: 320346.71875 normal_loss: 32026.99609375 gradient_loss: 3036.8427734375 double_well_term: 23.406539916992188 recon_loss: 2.298447370529175\n",
      "total_loss: 378129.375 normal_loss: 37803.5859375 gradient_loss: 3111.718994140625 double_well_term: 32.00856399536133 recon_loss: 3.038846254348755\n",
      "total_loss: 386481.9375 normal_loss: 38639.61328125 gradient_loss: 3181.455078125 double_well_term: 28.15279769897461 recon_loss: 2.5850462913513184\n",
      "total_loss: 30603156.0 normal_loss: 3060307.75 gradient_loss: 3246.142822265625 double_well_term: 22.779584884643555 recon_loss: 2.3410651683807373\n",
      "total_loss: 352178.625 normal_loss: 35204.796875 gradient_loss: 4007.784912109375 double_well_term: 50.2302131652832 recon_loss: 4.0351338386535645\n",
      "total_loss: 358661.96875 normal_loss: 35852.12890625 gradient_loss: 4853.57421875 double_well_term: 51.87324905395508 recon_loss: 4.028997898101807\n",
      "total_loss: 596338.5 normal_loss: 59619.078125 gradient_loss: 5773.86767578125 double_well_term: 50.42705535888672 recon_loss: 3.960585594177246\n",
      "total_loss: 407195.3125 normal_loss: 40699.97265625 gradient_loss: 6753.9794921875 double_well_term: 75.66448974609375 recon_loss: 5.239780902862549\n",
      "total_loss: 734338.0625 normal_loss: 73413.4140625 gradient_loss: 7782.0341796875 double_well_term: 75.3207778930664 recon_loss: 5.080516815185547\n",
      "total_loss: 7033046.0 normal_loss: 703282.75 gradient_loss: 8848.609375 double_well_term: 75.07596588134766 recon_loss: 5.51112699508667\n",
      "total_loss: 1260692.125 normal_loss: 126039.4765625 gradient_loss: 10162.3095703125 double_well_term: 119.31990051269531 recon_loss: 7.645923137664795\n",
      "total_loss: 299930.71875 normal_loss: 29959.0 gradient_loss: 11562.8916015625 double_well_term: 140.37327575683594 recon_loss: 8.471421241760254\n",
      "total_loss: 266520.75 normal_loss: 26612.134765625 gradient_loss: 13008.634765625 double_well_term: 168.1683349609375 recon_loss: 10.116029739379883\n",
      "total_loss: 288089.59375 normal_loss: 28768.7109375 gradient_loss: 14486.3916015625 double_well_term: 158.92105102539062 recon_loss: 9.868719100952148\n",
      "total_loss: 289780.28125 normal_loss: 28927.673828125 gradient_loss: 15983.705078125 double_well_term: 224.21136474609375 recon_loss: 11.94875717163086\n",
      "total_loss: 302572.3125 normal_loss: 30201.578125 gradient_loss: 17486.0703125 double_well_term: 253.80218505859375 recon_loss: 12.786865234375\n",
      "total_loss: 305136.375 normal_loss: 30454.974609375 gradient_loss: 18980.30078125 double_well_term: 262.30419921875 recon_loss: 13.450709342956543\n",
      "total_loss: 310558.25 normal_loss: 30993.291015625 gradient_loss: 20455.109375 double_well_term: 275.93255615234375 recon_loss: 14.487221717834473\n",
      "total_loss: 311751.15625 normal_loss: 31107.8828125 gradient_loss: 21900.0234375 double_well_term: 299.5379333496094 recon_loss: 15.381850242614746\n",
      "total_loss: 314494.1875 normal_loss: 31373.92578125 gradient_loss: 23306.1015625 double_well_term: 354.3689270019531 recon_loss: 16.750703811645508\n",
      "total_loss: 317082.46875 normal_loss: 31627.498046875 gradient_loss: 24665.83984375 double_well_term: 386.08843994140625 recon_loss: 17.47610092163086\n",
      "total_loss: 316708.4375 normal_loss: 31585.52734375 gradient_loss: 25973.177734375 double_well_term: 411.1242980957031 recon_loss: 18.230602264404297\n",
      "total_loss: 319250.40625 normal_loss: 31826.927734375 gradient_loss: 27223.380859375 double_well_term: 507.2389831542969 recon_loss: 20.163986206054688\n",
      "total_loss: 319984.34375 normal_loss: 31899.423828125 gradient_loss: 28413.189453125 double_well_term: 502.3948669433594 recon_loss: 20.356000900268555\n",
      "total_loss: 324954.71875 normal_loss: 32403.0 gradient_loss: 29540.658203125 double_well_term: 437.3317565917969 recon_loss: 19.19920539855957\n",
      "total_loss: 319681.40625 normal_loss: 31861.775390625 gradient_loss: 30605.4375 double_well_term: 543.6846923828125 recon_loss: 21.391727447509766\n",
      "total_loss: 321451.21875 normal_loss: 32029.26171875 gradient_loss: 31607.19921875 double_well_term: 616.4584350585938 recon_loss: 22.605024337768555\n",
      "total_loss: 325685.3125 normal_loss: 32449.75390625 gradient_loss: 32545.982421875 double_well_term: 633.0698852539062 recon_loss: 22.92461395263672\n",
      "total_loss: 324031.4375 normal_loss: 32289.10546875 gradient_loss: 33423.0 double_well_term: 579.2484130859375 recon_loss: 22.689653396606445\n",
      "total_loss: 325960.0625 normal_loss: 32476.8125 gradient_loss: 34239.95703125 double_well_term: 619.3745727539062 recon_loss: 23.016952514648438\n",
      "total_loss: 324565.46875 normal_loss: 32329.265625 gradient_loss: 34998.98046875 double_well_term: 681.524658203125 recon_loss: 24.12906837463379\n",
      "total_loss: 326481.59375 normal_loss: 32527.423828125 gradient_loss: 35702.44140625 double_well_term: 617.4287109375 recon_loss: 23.289264678955078\n",
      "total_loss: 326311.3125 normal_loss: 32504.498046875 gradient_loss: 36353.09375 double_well_term: 662.6220092773438 recon_loss: 24.01767921447754\n",
      "total_loss: 323673.34375 normal_loss: 32232.16015625 gradient_loss: 36953.796875 double_well_term: 730.4479370117188 recon_loss: 25.177719116210938\n",
      "total_loss: 324831.53125 normal_loss: 32359.900390625 gradient_loss: 37507.37890625 double_well_term: 621.9588012695312 recon_loss: 23.550065994262695\n",
      "total_loss: 327233.4375 normal_loss: 32592.359375 gradient_loss: 38016.71875 double_well_term: 685.560791015625 recon_loss: 24.41219711303711\n",
      "total_loss: 323164.0625 normal_loss: 32182.408203125 gradient_loss: 38484.640625 double_well_term: 705.7312622070312 recon_loss: 24.94054412841797\n"
     ]
    }
   ],
   "source": [
    "iters=100000\n",
    "loss_fn = PHASELoss(epsilon=eps, lambda_val=lam, mu=mu, ball_radius=0.001, use_normals=False)\n",
    "\n",
    "gt_mesh_path = \"Preimage_Implicit_DLTaskData/meshes/armadillo.obj\"\n",
    "\n",
    "normals = False\n",
    "\n",
    "if normals:\n",
    "    # Load normals if available\n",
    "    normals = load_pointcloud('bunny_normals.ply')\n",
    "else:    \n",
    "    normals = None\n",
    "\n",
    "model.train()\n",
    "\n",
    "model.to(\"cuda:0\")\n",
    "\n",
    "gt_points_all = sample_mesh_points(gt_mesh_path, n_points=10000)\n",
    "\n",
    "points_range = (gt_points_all.min(), gt_points_all.max())\n",
    "\n",
    "n_iter_points = 200\n",
    "\n",
    "for i in range(iters):\n",
    "    idx = torch.randint(0, gt_points_all.shape[0], (n_iter_points,  ))\n",
    "    selected_points = torch.gather(gt_points_all, 0, idx.unsqueeze(-1).expand(-1, 3)).to(\"cuda\")\n",
    "\n",
    "    # Zero gradients at the start of each iteration\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    # Forward pass and compute loss\n",
    "    if normals is not None:\n",
    "        loss, loss_components = loss_fn(model, selected_points, points_range, normals)\n",
    "    else:\n",
    "        loss, loss_components = loss_fn(model, selected_points, points_range)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update parameters\n",
    "    opt.step()\n",
    "    \n",
    "    # Print progress\n",
    "    if i %1000 == 0:\n",
    "        # run evaluation \n",
    "        try:\n",
    "            chamfer_dist, v, f = evaluate_reconstruction(model, gt_mesh_path, resolution=64, bounds=(-1.0, 1.0), n_points=10000)\n",
    "            print(f\"Chamfer distance: {chamfer_dist:.6f}\")\n",
    "            # create mesh with marching cubes\n",
    "            write_mesh(v,f,f'intermediates/mesh_{i}.ply')\n",
    "        except:\n",
    "            print(\"Error in evaluation\")\n",
    "\n",
    "        print(f\"Iter {i}/{iters}, Loss: {loss.item():.6f}, \"\n",
    "              f\"Grad: {loss_components['grad_term']:.6f}, \"\n",
    "              f\"DW: {loss_components['double_well']:.6f}, \"\n",
    "              f\"Recon: {loss_components['reconstruction']:.6f}, \"\n",
    "              f\"Norm: {loss_components['normal_constraint']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d8df06336734f3d5aefcb8cba5f6eb7ddbe787a24176311df2982a9f74ff87f0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('neurecon')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
